# -*- coding: utf-8 -*-
"""spend_analysis_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SWNI2xMFOHlEru0aE2U6wRICH2f7iC18

## 1. Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

"""## 2. Load Dataset

"""

df = pd.read_csv('/content/spend_analysis_dataset.csv')

"""## 3. Data Understanding

### Menampilkan 5 data teratas
"""

print(df.head())

"""### Cek informasi dataset

"""

print(df.info())

"""### Cek missing values

"""

print(df.isnull().sum())

"""### Cek duplikat

"""

print(df.duplicated().sum())

"""## 4. Exploratory Data Analysis (EDA)

### Statistik Deskriptif
"""

df.describe()

"""### Plot distribusi TotalCost

"""

plt.figure(figsize=(8,4))
sns.histplot(df['TotalCost'], kde=True)
plt.title('Distribusi TotalCost')
plt.xlabel('TotalCost')
plt.ylabel('Frekuensi')
plt.grid()
plt.show()

"""### Korelasi Quantity, UnitPrice, TotalCost"""

plt.figure(figsize=(6,5))
sns.heatmap(df[['Quantity', 'UnitPrice', 'TotalCost']].corr(), annot=True, cmap='coolwarm')
plt.title('Heatmap Korelasi Fitur Numerik')
plt.grid()
plt.show()

"""## 5. Data Preparation"""

# Pastikan PurchaseDate bertipe datetime
df['PurchaseDate'] = pd.to_datetime(df['PurchaseDate'])

# Gunakan hanya kolom PurchaseDate dan TotalCost
df = df[['PurchaseDate', 'TotalCost']]

# Set PurchaseDate menjadi index
df.set_index('PurchaseDate', inplace=True)

# Resample data menjadi bulanan (monthly)
df_monthly = df.resample('M').sum()

# Plot total cost per bulan
plt.figure(figsize=(12,6))
plt.plot(df_monthly, marker='o')
plt.title('Total Cost per Month')
plt.xlabel('Month')
plt.ylabel('Total Cost')
plt.grid()
plt.show()

"""## 6. Membuat Windowed Dataset"""

# Scaling data
scaler = MinMaxScaler()
df_scaled = scaler.fit_transform(df_monthly)

# Fungsi membuat window dataset
def create_windowed_dataset(series, window_size):
    X, y = [], []
    for i in range(len(series) - window_size):
        X.append(series[i:i+window_size])
        y.append(series[i+window_size])
    return np.array(X), np.array(y)

window_size = 3
X, y = create_windowed_dataset(df_scaled, window_size)

# Split data (80% train, 20% test)
split_idx = int(len(X)*0.8)
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

"""## 7. Modeling"""

#LTSM
model = Sequential([
    LSTM(64, activation='relu', input_shape=(window_size, 1)),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse')

"""## 8. Training"""

history = model.fit(
    X_train, y_train,
    epochs=100,
    validation_data=(X_test, y_test),
    callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],
    verbose=1
)

"""## 9. Evaluasi Model"""

# Prediksi
y_pred = model.predict(X_test)

# Inverse transform hasil prediksi dan y_test
y_pred_inv = scaler.inverse_transform(np.concatenate((np.zeros((len(y_pred), df_monthly.shape[1]-1)), y_pred), axis=1))[:, -1]
y_test_inv = scaler.inverse_transform(np.concatenate((np.zeros((len(y_test), df_monthly.shape[1]-1)), y_test), axis=1))[:, -1]

# Hitung metrik evaluasi
mae = mean_absolute_error(y_test_inv, y_pred_inv)
rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")

# Plot hasil prediksi vs aktual
plt.figure(figsize=(12,6))
plt.plot(y_test_inv, label='Actual')
plt.plot(y_pred_inv, label='Prediction')
plt.legend()
plt.title('Comparison: Actual vs Prediction')
plt.xlabel('Time')
plt.ylabel('Total Cost')
plt.grid()
plt.show()